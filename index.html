
<!DOCTYPE html>
<html>
<head>
    <title>IEEE Vis 2024 LLM4Vis tutorial</title>
    <!-- CSS only -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-1BmE4kWBq78iYhFldvKuhfTAU6auU8tT94WrHftjDbrCEXSU1oBoqyl2QvZ6jIW3" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.8.1/font/bootstrap-icons.css">
	<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">

    <style>
        .thumbnail {
            max-width: 100%;
            max-height: 100%;
        }
        .thumbnail-wrapper {
            width: 200px;
            height: 200px;
            display: block;
            margin: auto;
            padding-bottom: 20px;
        }
				i {
					margin-right: 20px;
				}
    </style>
</head>

<body data-new-gr-c-s-check-loaded="9.54.0" data-gr-ext-installed="">

<main class="container">
    <div class="bg-light p-5 rounded mt-3">
        <h1 class="text-center">LLM4Vis: Large Language Models for Information Visualization</h1>
        <h4 class="text-center">Half-day tutorial at <a href="https://ieeevis.org/year/2024/info/tutorials#LLM">IEEE Vis Conference 2024</a>.</h4></div>
    <div class="bg-light p-5 rounded mt-3">
        <h2 class="text-center">Overview</h2>
        <p class="lead">
This tutorial will provide an introduction to Large Language Models (LLMs) for interested researchers in the visualization (Vis)
community. It will first motivate why LLM4Vis is an important area
of research and how Large Language Models (LLMs) can be lever-
aged to solve various NLP tasks for visualizations. We will delve
into the basics of language models, covering model architectures,
including the Transformer architecture, and discuss various train-
ing methodologies, from pre-training to fine-tuning. We will then
dive deeper into Large Language Models, elucidating their emergent
abilities and practical applications in visualization tasks, including
prompt engineering, instruction tuning, and model variations for
processing text, tables, and images. In the final part, we will focus
on applying LLMs for information visualization, covering an array
of applications such as visual text analytics, natural language inter-
faces, chart question answering, text generation, visual analytics,
automatic visual story generation, and addressing issues of acces-
sibility and inclusivity in visualization. We will conclude with an
interactive discussion of future challenges for NLP+Vis applications.
The audience will include researchers interested in applying NLP
for visualizations as well as others who focus more generally on the
intersection of AI and visualization.        </p>
    </div>
    <div class="bg-light p-5 rounded mt-3">
        <h2 class="text-center">Materials</h2>
        <div class="container">
            <div class="row">
<h3>Tutorial Overview</h3>
<h4 style="font-size: 1.1em;">Part 1: Introduction [15 mins]</h4>

<ul style="margin-left: 20px;">
   <li>Why LLM + Vis?</li>
    <li>An overview of LLM + Vis Research</li>
    <li>An overview of the tutorial</li>
</ul>


<h4 style="font-size: 1.1em;">Part 2: LLMs for Visualizations [60 mins]</h4>

<ul style="margin-left: 20px;">
    <li>Basics of language models
        <ul>
            <li>Language modeling</li>
            <li>Model architectures</li>
			<ul>
            <li>Transformer architecture</li>
            <li>Encoder, decoder, encoder-decoder</li>
			</ul>
            <li>Model training</li>
			<ul>
            <li>Pre-training</li>
            <li>Fine-tuning</li>
			</ul>
        </ul>
    </li>
    <li>Large language models (LLMs)
        <ul>
            <li>Scaling LMs to LLMs</li>
            <li>Prompt engineering</li>
        <ul>
			
            <li>In-context learning</li>
            <li>Chain-of-thought prompts</li>
            <li>Program-aided language models</li>
            <li>ReAct: Reasoning + Action</li>
        </ul>

            <li>Multi-agent systems</li>
            <li>Multimodal LLMs</li>
        </ul>
    </li>
</ul>
<h4 style="font-size: 1.1em; color: #333;">Coffee Break &nbsp;<i class="fas fa-coffee"></i></h4>

<h4 style="font-size: 1.1em;">Part 3: LLM4Vis applications [50 mins]</h4>
<ul style="margin-left: 20px;">
    <li>LLM4Vis Design space</li>
    <li>Benchmark development</li>
    <li>Model development</li>
    <li>Evaluation</li>
</ul>

<h4 style="font-size: 1.1em;">Part 4: Challenges and research opportunities [15 mins]</h4>
<ul style="margin-left: 20px;">
    <li>Open research questions</li>
    <li>Research opportunities</li>
</ul>


				
				<!-- <p> <a href="">Overview</a></p>-->
				<h3>Slides</h3>
				<p> <a href="https://www.dropbox.com/scl/fi/84o0hzjbmhc4643mm27ey/LLM4Vis-Intro.pdf?rlkey=l5aak3ra1zn78e2w248kas764&dl=0">Part 1: Introduction</a></p>
				<!-- <p> <a href="">Part 2: Basics of Natural Language Processing</a></p> -->
				<p> <a href="https://www.dropbox.com/scl/fi/v68i2q1s4vhuq9oao22or/LLM4Vis-LM.pdf?rlkey=0xgoxrmqvq4e78wag8qlysxn4&dl=0">Part 2: LLMs for Visualizations</a></p>
				<p> <a href="https://www.dropbox.com/scl/fi/fs6kz4mp4hsrg7odg5i6u/LLM4Vis-Application-Future-v2.pdf?rlkey=1oox80m3vxzvefu3oxybnwir1&dl=0">LLM4Vis applications, Future Challenges</a></p>

            </div>
        </div>
    </div>

    <div class="bg-light p-5 rounded mt-3">
        <h2 class="text-center">Organizer</h2>
        <div class="container">
            <div class="row">
                <div class="col-sm text-center">
                    <div class="thumbnail-wrapper">
                        <img src="https://www.yorku.ca/enamulh/images/me2017.jpg" alt="Enamul Hoque" class="img-thumbnail thumbnail">
                    </div>
                    <h5><a href="https://www.yorku.ca/enamulh/">Enamul Hoque</a></h5>
										<p>Associate Professor, York University</p>
                    <a href = "mailto:enamulh@yorku.ca"><i class="bi bi-envelope" style="font-size: 2rem;"></i></a>
										<a href="https://twitter.com/Enamul_Hoque"><i class="bi bi-twitter" style="font-size: 2rem;"></i></a>
                </div>
                <!-- <div class="col-sm text-center">
                    <div class="thumbnail-wrapper">
                        <img src="https://raihanjoty.github.io/img/nav/shafiq.jpg" alt="Shafiq Joty" class="img-thumbnail thumbnail">
                    </div>
                    <h5><a href="https://raihanjoty.github.io/">Shafiq Joty</a></h5>
                    <p>Salesforce AI Research and Nanyang Technological University </p>
										<a href = "mailto:sjoty@salesforce.com"><i class="bi bi-envelope" style="font-size: 2rem;"></i></a>
										<a href="https://twitter.com/JotyShafiq"><i class="bi bi-twitter" style="font-size: 2rem;"></i></a>
                </div>-->

            </div>

        </div>
    </div>
</main>

<script src="/docs/5.1/dist/js/bootstrap.bundle.min.js" integrity="sha384-ka7Sk0Gln4gmtz2MlQnikT1wXgYsOg+OMhuP+IlRH9sENBO0LRn5q+8nbTov4+1p" crossorigin="anonymous"></script>
</body>
</html>
